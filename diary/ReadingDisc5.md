

Don Norman argues that what we typically call human error is often actually design error. People make mistakes not because they are careless or unintelligent, but because systems are poorly designed and fail to account for human limitations. Norman emphasizes that designers should create systems that anticipate human error rather than punish it.

Norman explains that people are creative and flexible—but not perfect. Machines, on the other hand, often demand extreme precision and consistency. Many errors occur because machines and procedures are designed for ideal conditions, not for the reality of human work under pressure, fatigue, or time stress. He points out that people are often forced to violate procedures to get their jobs done because the official rules make the work impossible under real conditions. Norman gives vivid examples, such as mode errors in airplane cockpits—cases where pilots believe they are adjusting one setting (angle of descent) but are actually adjusting another (speed of descent). These errors have led to fatal accidents. The root cause isn’t pilot negligence but poor design that hides the current “mode” from the user.

He insists that instead of demanding humans adapt to technology, designers should make machines that adapt to humans. This means designing interfaces that communicate clearly, tolerate small errors, and offer recovery options. For instance, computer systems could check for “sensibility” in inputs—like warning users if a bank transfer or medication dosage seems absurdly large.


